# Formula1 predictive modeling

Sports, especially motorsports, is heavily driven by data and analytics behind the scenes. As a viewer of Formula 1, I wanted to apply my skills and experience with machine learning models to a sport that I enjoyed watching and had knowledge in. As my first foray into this domain, I wanted to build a model to make predictions on the race results of drivers using past session results and weather data. There are two approaches for such a problem: Regression and classification. To predict the exact finishing position, a regression model would be much more suitable, however, I wanted to classify drivers into common buckets used to look at Grand Prix results, which meant that a classification model would be more suitable. \

#### The data

The dataset used in this project was compiled using the [OpenF1 API](https://openf1.org/url). I pulled session data from every Grand Prix weekend as well as PreSeason testing from 2022 to the present, due to the regulations being mostly similar during this period (ground effect era). For each session, I retained weather features and finishing positions for all drivers, including substitutions. I also included the team of each driver as well. To get this data, I wrote a short Python script (data_scraping.py) to scrape train/test data from the OpenF1 API for a set date range and data for the latest race weekend that we want to make predictions on. \

### Model Exploration

There are two approaches for such a problem: Regression and classification. To predict the exact finishing position, a regression model would be much more suitable, however, I wanted to classify drivers into common buckets used to look at Grand Prix results, which meant that a classification model would be more suitable. I wanted to classify the drivers' finishing position into the following classes: Winner, P2-P3), P4-P7 finish, P8-P10 (top 10 finish), and no points (all other finishing positions). However, this introduced one of the most common issues in ML problems: class imbalances. Since every race only has one winner, two drivers in P2/P3, etc, the classes are severly imbalanced. Some classification models such as Random Forest offer features to balance the class weights, which could be an option. Utilizing a resampling step in the pipeline would also be a viable solution. \
\
Two common classification models used in sports predictions are Random Forest and XGBoost. To see which would be more suitable for my dataset, I trained five models: Random Forest with a SMOTE resampling step, Random Forest with balanced class weights, Random Forest with both SMOTE and balanced class weights, XGBoost with SMOTE, and XGBoost with sample weights (which requires weights computed seperately). Since the classes are quite imbalanced, I opted to measure model performance using the area under the ROC curve (AUC).
